{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Based on example here: https://devklaus.wordpress.com/2018/03/11/sentiment-analysis-on-us-twitter-airlines-dataset-a-deep-learning-approach/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv',sep=';',index_col=0)\n",
    "val = pd.read_csv('../data/val.csv',sep=';',index_col=0)\n",
    "test = pd.read_csv('../data/test.csv',sep=';',index_col=0)\n",
    "df = train.append(val).append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "onehot_enc = MultiLabelBinarizer()\n",
    "onehot_enc.fit(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "word_tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "word_tokenizer.fit_on_texts(df['text'])\n",
    "\n",
    "\n",
    "#X = word_tokenizer.texts_to_sequences(train['text'].values.tolist() + val['text'].values.tolist() + test['text'].values.tolist())\n",
    "\n",
    "Xtrain = word_tokenizer.texts_to_matrix(train['text'])\n",
    "Xval = word_tokenizer.texts_to_matrix(val['text'])\n",
    "Xtest = word_tokenizer.texts_to_matrix(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2000) (5000, 3)\n",
      "(1000, 2000) (1000, 3)\n",
      "(1089, 2000) (1089, 3)\n"
     ]
    }
   ],
   "source": [
    "ytrain = pd.get_dummies(train['sentiment']).values\n",
    "yval = pd.get_dummies(val['sentiment']).values\n",
    "ytest = pd.get_dummies(test['sentiment']).values\n",
    "print(Xtrain.shape,ytrain.shape)\n",
    "print(Xval.shape,yval.shape)\n",
    "print(Xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnbc = BernoulliNB(binarize=None)\n",
    "bnbc.fit(Xtrain, train['sentiment'])\n",
    "np.mean(bnbc.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.724"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvm = LinearSVC()\n",
    "lsvm.fit(Xtrain, train['sentiment'])\n",
    "np.mean(lsvm.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uni + Bigram\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "Xtrain = vectorizer.fit_transform(train['text']).toarray()\n",
    "Xval = vectorizer.transform(val['text']).toarray()\n",
    "Xtest = vectorizer.transform(test['text']).toarray()\n",
    "\n",
    "bnbc = BernoulliNB(binarize=None)\n",
    "bnbc.fit(Xtrain, train['sentiment'])\n",
    "np.mean(bnbc.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm = LinearSVC()\n",
    "lsvm.fit(Xtrain, train['sentiment'])\n",
    "np.mean(lsvm.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just Bigram\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "Xtrain = vectorizer.fit_transform(train['text']).toarray()\n",
    "Xval = vectorizer.transform(val['text']).toarray()\n",
    "Xtest = vectorizer.transform(test['text']).toarray()\n",
    "\n",
    "bnbc = BernoulliNB(binarize=None)\n",
    "bnbc.fit(Xtrain, train['sentiment'])\n",
    "np.mean(bnbc.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.658"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm = LinearSVC()\n",
    "lsvm.fit(Xtrain, train['sentiment'])\n",
    "np.mean(lsvm.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uni + Bigram + Trigram\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "Xtrain = vectorizer.fit_transform(train['text']).toarray()\n",
    "Xval = vectorizer.transform(val['text']).toarray()\n",
    "Xtest = vectorizer.transform(test['text']).toarray()\n",
    "\n",
    "bnbc = BernoulliNB(binarize=None)\n",
    "bnbc.fit(Xtrain, train['sentiment'])\n",
    "np.mean(bnbc.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm = LinearSVC()\n",
    "lsvm.fit(Xtrain, train['sentiment'])\n",
    "np.mean(lsvm.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just Trigram\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "Xtrain = vectorizer.fit_transform(train['text']).toarray()\n",
    "Xval = vectorizer.transform(val['text']).toarray()\n",
    "Xtest = vectorizer.transform(test['text']).toarray()\n",
    "\n",
    "bnbc = BernoulliNB(binarize=None)\n",
    "bnbc.fit(Xtrain, train['sentiment'])\n",
    "np.mean(bnbc.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvm = LinearSVC()\n",
    "lsvm.fit(Xtrain, train['sentiment'])\n",
    "np.mean(lsvm.predict(Xval) == val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "batch_size = 512\n",
    "nepochs=20\n",
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 1/72 [01:26<1:42:19, 86.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 5000, 128, 64, 256, 0.9867999994277954, 0.7630000066757202]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nepochs=30\n",
    "from tqdm import tqdm\n",
    "with tqdm(total=2*3*4*3) as pbar:\n",
    "    for max_features in [5000,10000]:\n",
    "        for embed_dim in [64]:\n",
    "            for lstm_out in [32]:\n",
    "                for batch_size in [128]:\n",
    "                    word_tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "                    word_tokenizer.fit_on_texts(train['text'].values.tolist() + val['text'].values.tolist() + test['text'].values.tolist())\n",
    "\n",
    "\n",
    "                    X = word_tokenizer.texts_to_sequences(train['text'].values.tolist() + val['text'].values.tolist() + test['text'].values.tolist())\n",
    "                    X = pad_sequences(X)\n",
    "                    Xtrain = X[:len(train)]\n",
    "                    Xval = X[len(train):len(train)+len(val)]\n",
    "                    Xtest = X[len(train)+len(val):]\n",
    "\n",
    "\n",
    "\n",
    "                    model = Sequential()\n",
    "                    model.add(Embedding(max_features, embed_dim,input_length = Xtrain.shape[1]))\n",
    "                    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "                    model.add(Dense(3,activation='softmax'))\n",
    "                    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "                    #print(model.summary())\n",
    "\n",
    "                    history = model.fit(Xtrain, ytrain, epochs = nepochs, batch_size=batch_size, validation_data=(Xval, yval),verbose=False)\n",
    "                    res += [[max_features,embed_dim,lstm_out,batch_size] + history.history['acc'] + history.history['val_acc']]\n",
    "                    print([nepochs, max_features,embed_dim,lstm_out,batch_size] + [np.max(history.history['acc'])] + [np.max(history.history['val_acc'])])\n",
    "                    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nepochs</th>\n",
       "      <th>max_features</th>\n",
       "      <th>embed_dim</th>\n",
       "      <th>lstm_out</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_max</th>\n",
       "      <th>val_max</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.1782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8306</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.0716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.2154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.0374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.0420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.0468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nepochs  max_features  embed_dim  lstm_out  batch_size  train_max  \\\n",
       "18     10.0        5000.0      128.0      64.0       256.0     0.9462   \n",
       "15     10.0        5000.0       64.0      64.0       256.0     0.9322   \n",
       "22     10.0        5000.0      256.0     128.0       256.0     0.9666   \n",
       "21     10.0        5000.0      256.0      64.0       256.0     0.9638   \n",
       "20     10.0        5000.0      128.0     256.0       256.0     0.9552   \n",
       "6      10.0        1000.0      128.0      64.0       256.0     0.8488   \n",
       "3      10.0        1000.0       64.0      64.0       256.0     0.8330   \n",
       "4      10.0        1000.0       64.0     128.0       256.0     0.8306   \n",
       "17     10.0        5000.0       64.0     256.0       256.0     0.9368   \n",
       "23     10.0        5000.0      256.0     256.0       256.0     0.9704   \n",
       "5      10.0        1000.0       64.0     256.0       256.0     0.8250   \n",
       "12     10.0        5000.0       16.0      64.0       256.0     0.8826   \n",
       "16     10.0        5000.0       64.0     128.0       256.0     0.9406   \n",
       "9      10.0        1000.0      256.0      64.0       256.0     0.8504   \n",
       "8      10.0        1000.0      128.0     256.0       256.0     0.8414   \n",
       "7      10.0        1000.0      128.0     128.0       256.0     0.8394   \n",
       "10     10.0        1000.0      256.0     128.0       256.0     0.8614   \n",
       "19     10.0        5000.0      128.0     128.0       256.0     0.9482   \n",
       "11     10.0        1000.0      256.0     256.0       256.0     0.8532   \n",
       "1      10.0        1000.0       16.0     128.0       256.0     0.7844   \n",
       "0      10.0        1000.0       16.0      64.0       256.0     0.7860   \n",
       "13     10.0        5000.0       16.0     128.0       256.0     0.8680   \n",
       "14     10.0        5000.0       16.0     256.0       256.0     0.8740   \n",
       "2      10.0        1000.0       16.0     256.0       256.0     0.7748   \n",
       "\n",
       "    val_max    diff  \n",
       "18    0.768  0.1782  \n",
       "15    0.767  0.1652  \n",
       "22    0.764  0.2026  \n",
       "21    0.763  0.2008  \n",
       "20    0.762  0.1932  \n",
       "6     0.760  0.0888  \n",
       "3     0.759  0.0740  \n",
       "4     0.759  0.0716  \n",
       "17    0.758  0.1788  \n",
       "23    0.755  0.2154  \n",
       "5     0.755  0.0700  \n",
       "12    0.754  0.1286  \n",
       "16    0.753  0.1876  \n",
       "9     0.752  0.0984  \n",
       "8     0.752  0.0894  \n",
       "7     0.749  0.0904  \n",
       "10    0.749  0.1124  \n",
       "19    0.748  0.2002  \n",
       "11    0.747  0.1062  \n",
       "1     0.747  0.0374  \n",
       "0     0.744  0.0420  \n",
       "13    0.738  0.1300  \n",
       "14    0.733  0.1410  \n",
       "2     0.728  0.0468  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array(res)[:,:5],columns = ['nepochs','max_features','embed_dim','lstm_out','batch_size'])\n",
    "tr_acc = pd.DataFrame(np.array(res)[:,5:15])\n",
    "va_acc = pd.DataFrame(np.array(res)[:,15:25])\n",
    "df['train_max'] = tr_acc.max(axis=1)\n",
    "df['val_max'] = va_acc.max(axis=1)\n",
    "df['diff'] = df['train_max'] - df['val_max']\n",
    "df[(df['lstm_out']!=3)].sort_values('val_max',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(history.validation_data[0]).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.4062000021934509,\n",
       "  0.5275999977111816,\n",
       "  0.5857999985694885,\n",
       "  0.6772000019073486,\n",
       "  0.7309999984741211,\n",
       "  0.7759999981880188,\n",
       "  0.7929999979972839,\n",
       "  0.8005999985694885,\n",
       "  0.8136000009536744,\n",
       "  0.8380000006675721],\n",
       " 'loss': [1.0746020488739014,\n",
       "  0.9884465896606446,\n",
       "  0.8958369854927063,\n",
       "  0.7637522832870484,\n",
       "  0.6406505021095276,\n",
       "  0.5588097978591919,\n",
       "  0.5105084029197693,\n",
       "  0.48304083008766174,\n",
       "  0.46273315505981444,\n",
       "  0.43337293162345886],\n",
       " 'val_acc': [0.5220000109672547,\n",
       "  0.5660000066757203,\n",
       "  0.6179999914169312,\n",
       "  0.672000009059906,\n",
       "  0.7129999985694885,\n",
       "  0.7319999976158142,\n",
       "  0.7400000061988831,\n",
       "  0.7509999952316284,\n",
       "  0.7349999890327453,\n",
       "  0.7570000038146972],\n",
       " 'val_loss': [1.0360965976715089,\n",
       "  0.9714739093780518,\n",
       "  0.8775711927413941,\n",
       "  0.7391939158439637,\n",
       "  0.678727029800415,\n",
       "  0.6424490041732788,\n",
       "  0.6495523729324341,\n",
       "  0.6502507195472718,\n",
       "  0.6688855495452881,\n",
       "  0.7119390687942505]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
